{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87418bed",
   "metadata": {},
   "source": [
    "# Web Search & Summarization Agent with Smolagent\n",
    "\n",
    "In this notebook, we will build a natural language agent capable of:\n",
    "\n",
    "- Searching the web based on user queries  \n",
    "- Automatically extracting and summarizing content from the resulting pages  \n",
    "- Returning structured answers, powered by a large language model (LLM)\n",
    "\n",
    "We will use the [`smolagents`](https://github.com/smol-ai/smolagent) framework to connect tools like `DuckDuckGo` search and HTML scraping with an OpenAI model.\n",
    "\n",
    "\n",
    "## Example use case\n",
    "\n",
    "> \"Summarize the Hugging Face blog post about open LLMs from 2023.\"\n",
    "\n",
    "The agent will:\n",
    "1. Search the web for that blog post\n",
    "2. Find the best link\n",
    "3. Read and clean the content of the page\n",
    "4. Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e72b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from smolagents import CodeAgent\n",
    "from smolagents import OpenAIServerModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d305bd5",
   "metadata": {},
   "source": [
    "### Tool: `web_search(query: str)`\n",
    "\n",
    "This tool enables the agent to **search the web using DuckDuckGo**.  \n",
    "It returns the **top 3 relevant results**, each with a title and a clickable URL.\n",
    "\n",
    "LLMs don’t have live access to the internet by default.  \n",
    "\n",
    "Example queries the agent might use this tool for:\n",
    "- `\"latest news about open-source LLMs\"`\n",
    "- `\"hugging face blog post on quantization\"`\n",
    "- `\"datacraft website upcoming events\"`\n",
    "\n",
    "#### How it works\n",
    "\n",
    "- The tool uses the [`ddgs`](https://pypi.org/project/ddgs/) library (DuckDuckGo Search).\n",
    "- It performs a web search for the given query.\n",
    "- It returns the first 3 results as a bullet list: `\"- [title] ([url])\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34341e4f",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "\n",
    "Go to [tools.py](./tools.py) and fill the tool called `web_search` that takes a query as input and returns the top 3 results with title and URL.\n",
    "\n",
    "Do not forget to fill the docstrings information too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fe080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_smolagents_mcp.tools import web_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d902abe",
   "metadata": {},
   "source": [
    "The `query_events_db` tool is defined in the [tools.py](./tools.py) file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f47984",
   "metadata": {},
   "source": [
    "### Tool: `summarize_url(url: str)`\n",
    "\n",
    "This tool allows the agent to **extract and summarize the main textual content** from a public web page.\n",
    "\n",
    "It plays a key role in helping the agent “read the web” by turning a full HTML page into a clean, readable excerpt — ready to be summarized by the LLM.\n",
    "\n",
    "After finding a link with `web_search(...)`, the agent needs to access and understand what’s on that page.  \n",
    "\n",
    "This tool:\n",
    "- Downloads the page (`requests`)\n",
    "- Parses it (`BeautifulSoup`)\n",
    "- Removes all unnecessary tags (e.g. `<script>`, `<style>`, `<noscript>`)\n",
    "- Extracts **only the visible text**\n",
    "- Returns the **first 60 lines** as a preview, making it manageable for summarization\n",
    "\n",
    "\n",
    "\n",
    "- **Input**: a valid URL (starting with `http://` or `https://`)\n",
    "- **Output**: a cleaned block of raw text, ready to be passed to the model\n",
    "\n",
    "If the page is unreachable, the tool returns a fallback error message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9362e",
   "metadata": {},
   "source": [
    "The `summarize_url` tool is defined in the [tools.py](./tools.py) file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4592fe1",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "\n",
    "Go to [tools.py](./tools.py) and fill the tool called `summarize_url` that takes a URL as input and returns the summary of the page.\n",
    "\n",
    "Do not forget to fill the docstrings information too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_smolagents_mcp.tools import summarize_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIServerModel(\n",
    "    model_id=\"gpt-4o\",\n",
    "    api_base=\"https://api.openai.com/v1\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee778360",
   "metadata": {},
   "source": [
    "### Creating an Agent with Multiple Tools\n",
    "\n",
    "Now that we’ve defined two tools — `web_search` and `summarize_url` — we can combine them into a single agent.\n",
    "\n",
    "By passing **both tools** to the `CodeAgent`, the model gains the ability to:\n",
    "\n",
    "1. **Search the web** for relevant information (via `web_search`)\n",
    "2. **Read and extract the content** of a webpage (via `summarize_url`)\n",
    "\n",
    "\n",
    "The `CodeAgent` uses the language model to reason about the user’s question and **decide when and how to call each tool**.  \n",
    "This means you don’t need to manually control the flow — the agent will:\n",
    "\n",
    "- Interpret the user's intent\n",
    "- Call one or both tools as needed\n",
    "- Return a natural language answer\n",
    "\n",
    " For example, if you ask:\n",
    "> *\"Summarize the latest blog post from Hugging Face about open LLMs\"*  \n",
    " \n",
    " The agent might:\n",
    "1. Use `web_search` to find the link\n",
    "2. Use `summarize_url` on that link\n",
    "3. Return a final summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacb50e",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "\n",
    "Register both tools defined above to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(\n",
    "    tools=[...],\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c034117",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "\n",
    "Have fun: try to run queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is datacraft paris?\"\n",
    "agent.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
